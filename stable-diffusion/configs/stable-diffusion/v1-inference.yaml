sampler_config:                  # sampler config params
    linear_start: 0.00085
    linear_end: 0.0120
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    cosine_s: 8e-3

model_config:
    image_size: 64
    channels: 4
    scale_factor: 0.18215
    sd_ckpt: /root/qiaozhiqiang/workspace/vision_open_source/pretrained_models/stable-diffusion-v1-5/v1-5-pruned.ckpt

    unet_config:
        params:
            image_size: 32 # unused
            in_channels: 4
            out_channels: 4
            model_channels: 320
            attention_resolutions: [ 4, 2, 1 ]
            num_res_blocks: 2
            channel_mult: [ 1, 2, 4, 4 ]
            num_heads: 8
            use_spatial_transformer: True
            transformer_depth: 1
            context_dim: 768
            use_checkpoint: True
            legacy: False

    first_stage_config:
        params:
            embed_dim: 4
            ddconfig:
                double_z: true
                z_channels: 4
                resolution: 256
                in_channels: 3
                out_ch: 3
                ch: 128
                ch_mult:
                - 1
                - 2
                - 4
                - 4
                num_res_blocks: 2
                attn_resolutions: []
                dropout: 0.0

    cond_stage_config:
        ckpt: /root/qiaozhiqiang/workspace/vision_open_source/pretrained_models/clip-vit-large-patch14



